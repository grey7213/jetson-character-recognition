# Jetson Nanoå­—ç¬¦è¯†åˆ«ç³»ç»Ÿ - å¿«é€Ÿå‚è€ƒå¡

> ğŸš€ **è¿™æ˜¯ä¸€ä»½å¿«é€Ÿå‚è€ƒæŒ‡å—ï¼Œé€‚åˆå·²ç»å®Œæˆåˆå§‹å®‰è£…çš„ç”¨æˆ·**

## ğŸ“‹ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

### ğŸ”§ ç³»ç»Ÿç®¡ç†
```bash
# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
python3 scripts/test_system.py

# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# æŸ¥çœ‹GPUçŠ¶æ€
nvidia-smi

# æ€§èƒ½ä¼˜åŒ–
sudo nvpmodel -m 0 && sudo jetson_clocks
```

### ğŸ“Š æ•°æ®ç”Ÿæˆ
```bash
# ç”Ÿæˆå®Œæ•´æ•°æ®é›†ï¼ˆæ¯ä¸ªå­—ç¬¦100å¼ å›¾ç‰‡ï¼‰
python3 data/tools/data_generator.py --output data/synthetic --count 100 --yolo --samples

# ç”Ÿæˆå°æ•°æ®é›†ï¼ˆå¿«é€Ÿæµ‹è¯•ç”¨ï¼‰
python3 data/tools/data_generator.py --output data/synthetic --count 20 --yolo --samples

# æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®
ls data/synthetic/
```

### ğŸ“ æ¨¡å‹è®­ç»ƒ
```bash
# æ ‡å‡†è®­ç»ƒï¼ˆæ¨èï¼‰
python3 scripts/train_model.py --dataset synthetic --epochs 100 --batch-size 8

# å¿«é€Ÿè®­ç»ƒï¼ˆæµ‹è¯•ç”¨ï¼‰
python3 scripts/train_model.py --dataset synthetic --epochs 20 --batch-size 4

# å†…å­˜ä¸è¶³æ—¶ä½¿ç”¨
python3 scripts/train_model.py --dataset synthetic --epochs 50 --batch-size 2
```

### ğŸš€ æ¨¡å‹ä½¿ç”¨
```bash
# å®æ—¶æ£€æµ‹
python3 scripts/run_detection.py models/custom/synthetic_trained.pt

# æ¼”ç¤ºç¨‹åº
python3 scripts/demo.py

# ç³»ç»ŸéªŒè¯
python3 scripts/final_system_validation.py
```

---

## ğŸ¯ Python API é€ŸæŸ¥

### åŸºæœ¬æ£€æµ‹
```python
from src.models.yolo_character_detector import YOLOCharacterDetector
import cv2

# åŠ è½½æ¨¡å‹
detector = YOLOCharacterDetector()
detector.load_model("models/custom/synthetic_trained.pt")

# æ£€æµ‹å›¾ç‰‡
image = cv2.imread("test.jpg")
detections = detector.predict(image)

# æ˜¾ç¤ºç»“æœ
for det in detections:
    print(f"{det['class_name']}: {det['confidence']:.2f}")
```

### å®æ—¶æ£€æµ‹
```python
from src.inference.realtime_detector import RealtimeCharacterDetector

# è®¾ç½®å›è°ƒå‡½æ•°
def on_detection(result):
    print(f"æ£€æµ‹åˆ° {len(result.detections)} ä¸ªå­—ç¬¦")

# å¯åŠ¨æ£€æµ‹
detector = RealtimeCharacterDetector("models/custom/synthetic_trained.pt")
detector.set_detection_callback(on_detection)
detector.start_detection()
```

### æ‰¹é‡å¤„ç†
```python
from src.inference.batch_processor import BatchProcessor

# å¤„ç†æ•´ä¸ªç›®å½•
processor = BatchProcessor("models/custom/synthetic_trained.pt")
results = processor.process_directory("input_images/")

# æŸ¥çœ‹ç»“æœ
for image_path, detections in results.items():
    print(f"{image_path}: {len(detections)} ä¸ªå­—ç¬¦")
```

---

## âš ï¸ å¸¸è§é—®é¢˜å¿«é€Ÿè§£å†³

### é—®é¢˜ï¼šå‘½ä»¤æ‰¾ä¸åˆ°
```bash
# æ£€æŸ¥å½“å‰ç›®å½•
pwd
# åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š/home/ç”¨æˆ·å/projects/jetson-character-recognition

# å¦‚æœä¸åœ¨ï¼Œåˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
cd ~/projects/jetson-character-recognition
```

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³
```bash
# åˆ›å»ºäº¤æ¢æ–‡ä»¶
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# å‡å°‘batch-size
python3 scripts/train_model.py --dataset synthetic --epochs 100 --batch-size 2
```

### é—®é¢˜ï¼šæ‘„åƒå¤´æ— æ³•ä½¿ç”¨
```bash
# æ£€æŸ¥æ‘„åƒå¤´
lsusb | grep -i camera

# æµ‹è¯•æ‘„åƒå¤´
sudo apt install cheese -y
cheese
```

### é—®é¢˜ï¼šè®­ç»ƒä¸­æ–­
```bash
# ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ
python3 scripts/train_model.py --dataset synthetic --epochs 100 --resume models/custom/last_checkpoint.pt
```

### é—®é¢˜ï¼šè¯†åˆ«å‡†ç¡®ç‡ä½
```bash
# é‡æ–°ç”Ÿæˆæ›´å¤šæ•°æ®
python3 data/tools/data_generator.py --output data/synthetic --count 200 --yolo

# å¢åŠ è®­ç»ƒè½®æ•°
python3 scripts/train_model.py --dataset synthetic --epochs 200 --batch-size 8
```

---

## ğŸ“ é‡è¦æ–‡ä»¶ä½ç½®

### æ¨¡å‹æ–‡ä»¶
```
models/custom/synthetic_trained.pt     # è®­ç»ƒå¥½çš„æ¨¡å‹
models/custom/training_logs/           # è®­ç»ƒæ—¥å¿—
models/model_info.yaml                 # æ¨¡å‹ä¿¡æ¯
```

### æ•°æ®æ–‡ä»¶
```
data/synthetic/                        # ç”Ÿæˆçš„è®­ç»ƒæ•°æ®
data/synthetic/samples/                # æ ·æœ¬å›¾ç‰‡
data/processed/yolo_format/            # YOLOæ ¼å¼æ•°æ®
```

### é…ç½®æ–‡ä»¶
```
config/model_config.yaml               # æ¨¡å‹é…ç½®
config/camera_config.yaml              # æ‘„åƒå¤´é…ç½®
requirements.txt                       # Pythonä¾èµ–
```

### è„šæœ¬æ–‡ä»¶
```
scripts/train_model.py                 # è®­ç»ƒè„šæœ¬
scripts/run_detection.py               # å®æ—¶æ£€æµ‹è„šæœ¬
scripts/demo.py                        # æ¼”ç¤ºè„šæœ¬
scripts/test_system.py                 # ç³»ç»Ÿæµ‹è¯•è„šæœ¬
```

---

## ğŸ” æ€§èƒ½ç›‘æ§

### ç³»ç»Ÿèµ„æºç›‘æ§
```bash
# CPUå’Œå†…å­˜ä½¿ç”¨
htop

# GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# ç£ç›˜ä½¿ç”¨
df -h

# æ¸©åº¦ç›‘æ§
cat /sys/class/thermal/thermal_zone*/temp
```

### è®­ç»ƒè¿›åº¦ç›‘æ§
è®­ç»ƒæ—¶è§‚å¯Ÿè¿™äº›æŒ‡æ ‡ï¼š
- **Lossï¼ˆæŸå¤±ï¼‰**ï¼šåº”è¯¥é€æ¸ä¸‹é™
- **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**ï¼šåº”è¯¥é€æ¸ä¸Šå‡
- **Val Lossï¼ˆéªŒè¯æŸå¤±ï¼‰**ï¼šä¸åº”è¯¥æŒç»­ä¸Šå‡
- **FPS**ï¼šå¤„ç†é€Ÿåº¦ï¼Œè¶Šé«˜è¶Šå¥½

### æ£€æµ‹æ€§èƒ½ç›‘æ§
```python
# ç®€å•æ€§èƒ½æµ‹è¯•
import time
import cv2
from src.models.yolo_character_detector import YOLOCharacterDetector

detector = YOLOCharacterDetector()
detector.load_model("models/custom/synthetic_trained.pt")

# æµ‹è¯•å›¾ç‰‡
image = cv2.imread("test.jpg")

# è®¡æ—¶æµ‹è¯•
start_time = time.time()
detections = detector.predict(image)
end_time = time.time()

print(f"æ£€æµ‹æ—¶é—´: {end_time - start_time:.3f}ç§’")
print(f"FPS: {1/(end_time - start_time):.1f}")
print(f"æ£€æµ‹åˆ°: {len(detections)} ä¸ªå­—ç¬¦")
```

---

## ğŸ¨ è‡ªå®šä¹‰é…ç½®

### è°ƒæ•´æ£€æµ‹å‚æ•°
```python
# åœ¨ä»£ç ä¸­è°ƒæ•´å‚æ•°
detections = detector.predict(
    image,
    confidence=0.5,      # ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)
    nms_threshold=0.4    # é‡å æ£€æµ‹è¿‡æ»¤é˜ˆå€¼
)
```

### ä¿®æ”¹è®­ç»ƒå‚æ•°
```bash
# è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
python3 scripts/train_model.py \
    --dataset synthetic \
    --epochs 150 \
    --batch-size 16 \
    --output-dir models/custom \
    --data-dir data
```

### æ‘„åƒå¤´è®¾ç½®
ç¼–è¾‘ `config/camera_config.yaml`ï¼š
```yaml
camera:
  device_id: 0          # æ‘„åƒå¤´è®¾å¤‡å·
  width: 640            # å›¾åƒå®½åº¦
  height: 480           # å›¾åƒé«˜åº¦
  fps: 30               # å¸§ç‡
  auto_exposure: true   # è‡ªåŠ¨æ›å…‰
```

---

## ğŸ“ è·å–å¸®åŠ©

### æŸ¥çœ‹æ—¥å¿—
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f models/custom/training_logs/train.log

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
journalctl -u your-service-name -f
```

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†è¾“å‡º
python3 scripts/train_model.py --dataset synthetic --epochs 100 --verbose

# Pythonè°ƒè¯•æ¨¡å¼
python3 -u scripts/run_detection.py models/custom/synthetic_trained.pt
```

### ç¤¾åŒºæ”¯æŒ
- **GitHub Issues**: https://github.com/grey7213/jetson-character-recognition/issues
- **NVIDIAè®ºå›**: https://forums.developer.nvidia.com/
- **è¯¦ç»†æ–‡æ¡£**: [å®Œæ•´åˆå­¦è€…æŒ‡å—](BEGINNER_GUIDE_CN.md)

---

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿå¼€å§‹æµç¨‹

### æ–°ç”¨æˆ·ï¼ˆ5åˆ†é’Ÿå¿«é€Ÿæµ‹è¯•ï¼‰
```bash
# 1. ç”Ÿæˆå°æ•°æ®é›†
python3 data/tools/data_generator.py --output data/synthetic --count 10 --yolo

# 2. å¿«é€Ÿè®­ç»ƒ
python3 scripts/train_model.py --dataset synthetic --epochs 10 --batch-size 4

# 3. æµ‹è¯•ç³»ç»Ÿ
python3 scripts/test_system.py

# 4. è¿è¡Œæ¼”ç¤º
python3 scripts/demo.py
```

### æ­£å¼ä½¿ç”¨ï¼ˆå®Œæ•´æµç¨‹ï¼‰
```bash
# 1. ç”Ÿæˆå®Œæ•´æ•°æ®é›†
python3 data/tools/data_generator.py --output data/synthetic --count 100 --yolo --samples

# 2. æ­£å¼è®­ç»ƒ
python3 scripts/train_model.py --dataset synthetic --epochs 100 --batch-size 8

# 3. ç³»ç»ŸéªŒè¯
python3 scripts/final_system_validation.py

# 4. å®æ—¶æ£€æµ‹
python3 scripts/run_detection.py models/custom/synthetic_trained.pt
```

---

**ğŸ’¡ æç¤ºï¼šå°†æ­¤é¡µé¢åŠ å…¥ä¹¦ç­¾ï¼Œæ–¹ä¾¿éšæ—¶æŸ¥é˜…ï¼**
